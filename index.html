<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>EvMic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Experiment Section</title>
  <style>
      body {
          font-family: Arial, sans-serif;
          margin: 0;
          padding: 0;
          background-color: #f9f9f9;
          color: #333;
      }
      div.custom-width{
        width: 100%; 
        max-width: 1000px; 
        /* margin-left: 20%; */
        margin: 0 auto;
        /* max-width: fit-content; */
      }
      img.custom-width{
        width: 100%; 
        max-width: 1000px; 
      }
      img.custom-width-teaser{
        width: 100%; 
        max-width: 1000px; 
        margin: 0 auto;
      }

      .experiment-section {
          display: flex;
          flex-wrap: wrap;
          justify-content: space-between;
          align-items: flex-start; /* Align tops of all items */
          gap: 1.5rem;
          padding: 2rem;
          max-width: 1200px;
          margin: 0 auto;
      }

      .item {
          flex: 1;
          min-width: 250px;
          max-width: 300px;
          text-align: center;
      }

      .item img {
          width: 100%;
          height: 100%; /* Set a fixed height for all images */
          object-fit: cover; /* Maintain aspect ratio and crop if necessary */
          border: 1px solid #ccc;
          border-radius: 5px;
          padding: 0rem;
          background-color: #fff;
      }

      .spectrogram {
          display: flex;
          flex-direction: column;
          align-items: center;
          gap: 1rem;
      }

      .spectrogram img {
          width: 100%;
          height: 100%; /* Match height with other images */
          object-fit: cover;
      }

      .audio-player {
          display: flex;
          justify-content: center;
          align-items: center;
          gap: 1rem;
          width: 100%;
          padding: 0rem;
          border: 1px solid #ccc;
          border-radius: 5px;
          background-color: #fff;
      }

      .audio-player audio {
          width: 100%;
          /* height: 100%; */
      }

      .description {
          margin-top: 0.5rem;
          font-size: 0.9rem;
          color: #555;
          text-align: bottom;
      }

      .title {
          font-size: 1rem;
          font-weight: bold;
          margin-bottom: 0.5rem;
      }
      .background-container {
            /* position: relative; */
            margin: 0 auto;
            width: 1000px;
            height: 346px;
            background-image: url('./static/images/teaser.png');
            background-size: cover;
            background-position: center;
        }
        
        .audio-button {
            position: relative;
            width: 35px;
            height: 35px;
            background-color: rgba(255, 0, 0, 0.7);
            border-radius: 50%;
            border: 2px solid white;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: transform 0.2s, background-color 0.2s;
            /* transform: translate(-50%, -50%); Center the button on its position */
        }
        
        .audio-button:hover {
            /* transform: translate(-50%, -50%) scale(1.1); */
            background-color: rgba(255, 0, 0, 0.9);
        }
        
        .audio-button::after {
            content: '';
            width: 0;
            height: 0;
            border-top: 8px solid transparent;
            border-left: 16px solid white;
            border-bottom: 8px solid transparent;
            margin-left: 4px;
        }
        
        /* Button positions - you'll need to adjust these based on your image */
        #button1 {
            left: 180px;
            top: 90px;
        }
        
        #button2 {
            left: 63px;
            top: 40px;
        }
        
        #button3 {
            left: 370px;
            top: 10px;
        }
        
        #button4 {
            left: 450px;
            top: -25px;
        }
        
        #button5 {
            left: 100px;
            top: 75px;
        }
        #button6 {
            left: 411px;
            top: 80px;
        }
  </style>
  <style>
   h4 { text-align: center;}
</style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">EvMic: Event-based Non-contact Sound Recovery from Effective Spatial-temporal Modeling</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Hao Yin</a><sup>2,1*</sup>,</span>
                <span class="author-block">
                  <a href="https://guoshi28.github.io/" target="_blank">Shi Guo</a><sup>1*</sup>,</span>
                  <span class="author-block">
                    <a href="https://stephenjia.github.io/" target="_blank">Xu Jia</a><sup>2†</sup>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com.hk/citations?user=D8VMkA8AAAAJ&hl=en" target="_blank">Xudong Xu</a><sup>1</sup>,</span>
                      <span class="author-block">
                        <a href="https://scholar.google.com.sg/citations?user=bUtRE5UAAAAJ&hl=zh-CN" target="_blank">Lu Zhang</a><sup>2</sup>,</span>
                        <span class="author-block">
                          <a href="https://scholar.google.com/citations?user=-QtVtNEAAAAJ&hl=en" target="_blank">Si Liu</a><sup>4</sup>,</span>
                          <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=nVgPQpoAAAAJ&hl=en&oi=ao" target="_blank">Dong Wang</a><sup>2</sup>,</span>
                            <span class="author-block">
                              <a href="https://scholar.google.com/citations?user=D3nE0agAAAAJ&hl=en" target="_blank">Huchuan Lu</a><sup>2</sup>,</span>
                              <span class="author-block">
                                <a href="https://tianfan.info/" target="_blank">Tianfan Xue</a><sup>3,1</sup>,</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Shanghai AI Laboratory,<sup>2</sup>Dalian University of Technology,<br><sup>3</sup>The Chinese University of Hong Kong,<sup>4</sup>Beihang University</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution,<sup>†</sup>Indicates Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/yyzq1/EvMic/tree/main" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<body>
<section class="section hero is-small">
  <h2 class="title is-3" style="text-align:center;">Teaser</h2>
  <div class="background-container">
  <div id="button1" class="audio-button" onclick="playAudio('chipbag')"></div>
  <div id="button2" class="audio-button" onclick="playAudio('speaker')"></div>
  <div id="button3" class="audio-button" onclick="playAudio('speaker1')"></div>
  <div id="button4" class="audio-button" onclick="playAudio('speaker2')"></div>
  <div id="button5" class="audio-button" onclick="playAudio('microphone')"></div>
  <div id="button6" class="audio-button" onclick="playAudio('stereo')"></div>
  
  <!-- Audio Elements -->
  <audio id="chipbag" src="./static/audios/chipbagspeech_ours.wav"></audio>
  <audio id="speaker" src="./static/audios/speakerspeech_ours.wav"></audio>
  <audio id="speaker1" src="./static/audios/left.wav"></audio>
  <audio id="speaker2" src="./static/audios/right.wav"></audio>
  <audio id="microphone" src="./static/audios/speech_microphone.wav"></audio>
  <audio id="stereo" src="./static/audios/stereo.wav"></audio>
</div>
  <p style="text-align:center;">We propose a novel non-contact sound recovery system based on event cameras.</p>
</section>
<script>
  function playAudio(id) {
            // Stop all audio first
            document.querySelectorAll('audio').forEach(audio => {
                audio.pause();
                audio.currentTime = 0;
            });
            
            // Play the selected audio
            const audio = document.getElementById(id);
            audio.play();
        }
        
        // Replace placeholder with your actual image
        // In a real implementation, you would use your own image URL
        document.querySelector('.background-container').style.backgroundImage = "url('./static/images/teaser.png')";
</script>
<body>
<!-- End Teaser -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            When sound waves hit an object, they induce vibrations that produce high-frequency and subtle visual changes, which can be used for recovering the sound. Early studies always encounter trade-offs related to sampling rate, bandwidth, field of view, and the simplicity of the optical path. Recent advances in event camera hardware show good potential for its application in visual sound recovery, because of its superior ability in capturing high-frequency signals. However, existing event-based vibration recovery methods are still sub-optimal for sound recovery. In this work, we propose a novel pipeline for non-contact sound recovery, fully utilizing spatial-temporal information from the event stream. We first generate a large training set using a novel simulation pipeline. Then we designed a network that leverages the sparsity of events to capture spatial information and uses Mamba to model long-term temporal information. Lastly, we train a spatial aggregation block to aggregate information from different locations to further improve signal quality. To capture event signals caused by sound waves, we also designed an imaging system using a laser matrix to enhance the gradient and collected multiple data sequences for testing. Experimental results on synthetic and real-world data demonstrate the effectiveness of our method. Our code and data will be publicly available upon acceptance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <h4 class="title is-3" style="text-align:center;">Method</h4>
    <figure style="text-align:center;">
      <img class="custom-width" src="static/images/framework.png" alt="Framework Image">
      <!-- <figcaption style="color:#555; ">
        <div class="content has-text-justified">
        (a) Overview of our proposed network architecture. The event stream is processed into voxel grids, from which patches centered around the speckles are selected. First, the patches are input into a sparse convolution-based lightweight backbone to extract visual features. Next, a spatial attention block aggregates the information in the different patches. Finally, Mamba is employed to model long-term temporal information and reconstruct the audio that caused the object’s vibration. (b) and (c) illustrate the detailed structure of SAB and SSM. (c) At time t g<sub>t</sub> is the input feature, o<sub>t</sub> is the output and h<sub>t</sub> denotes the hidden state. A, B, and C are the gating weights optimized by Mamba. Δ is used to discretize the continuous parameters A and B.
      </div>
      </figcaption> -->
      <div class="content has-text-justified custom-width">
        (a) Overview of our proposed network architecture. The event stream is processed into voxel grids, from which patches centered around the speckles are selected. First, the patches are input into a sparse convolution-based lightweight backbone to extract visual features. Next, a spatial attention block aggregates the information in the different patches. Finally, Mamba is employed to model long-term temporal information and reconstruct the audio that caused the object’s vibration. (b) and (c) illustrate the detailed structure of SAB and SSM. (c) At time t g<sub>t</sub> is the input feature, o<sub>t</sub> is the output and h<sub>t</sub> denotes the hidden state. A, B, and C are the gating weights optimized by Mamba. Δ is used to discretize the continuous parameters A and B.
      <div>
    </img>
    </figure>
  </div>
</section>
<!-- End image carousel -->

<!--video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3" style="text-align:center;">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="./static/videos/supp.mp4" frameborder="0" autoplay="false" allow="encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video -->

<!--experiment result-->
<body>
    <h4 class="title is-3">Experiment Results</h4>
    <section class="experiment-section">
        <!-- Experiment Setup -->
        <div class="item">
            <div class="title">Experiment Setup</div>
            <img src="./static/images/chipbag_rgb.png" alt="Experiment Setup">
            <div class="description">Capturing a chipbag while playing MIDI audio of "Mary has a little lamb..."</div>
        </div>

        <!-- Visualized Events -->
        <div class="item">
            <div class="title">Visualized Events</div>
            <img src="./static/images/chipbag_event.png" alt="Visualized Events">
            <!-- <div class="description">This is a brief description of the experiment setup.</div> -->
        </div>

        <!-- Microphone -->
        <div class="item">
            <div class="title">Microphone</div>
            <img src="./static/images/midi_microphone.png" alt="Microphone Spectrogram">
            <div class="audio-player">
                <audio controls>
                    <source src="./static/audios/midi_microphone.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <!-- Recovered -->
        <div class="item">
            <div class="title">Recovered</div>
            <img src="./static/images/chipbagmidi_recovered.png" alt="Recovered Spectrogram">
            <div class="audio-player">
                <audio controls>
                    <source src="./static/audios/chipbagmidi_ours.wav" type="audio/mpeg">
                </audio>
            </div>
        </div>

        <!-- Experiment Setup -->
        <div class="item">
          <!-- <div class="title">Experiment Setup</div> -->
          <img src="./static/images/chipbag_rgb.png" alt="Experiment Setup">
          <div class="description">Capturing a chipbag while playing Speech of "Mary has a little lamb..."</div>
      </div>

      <!-- Visualized Events -->
      <div class="item">
          <!-- <div class="title">Visualized Events</div> -->
          <img src="./static/images/chipbag_event.png" alt="Visualized Events">
          <!-- <div class="description">This is a brief description of the experiment setup.</div> -->
      </div>

      <!-- Microphone -->
      <div class="item">
          <!-- <div class="title">Microphone</div> -->
          <img src="./static/images/speech_microphone.png" alt="Microphone Spectrogram">
          <div class="audio-player">
              <audio controls>
                  <source src="./static/audios/speech_microphone.wav" type="audio/mpeg">
              </audio>
          </div>
      </div>

      <!-- Recovered -->
      <div class="item">
          <!-- <div class="title">Recovered</div> -->
          <img src="./static/images/chipbagspeech_recovered.png" alt="Recovered Spectrogram">
          <div class="audio-player">
              <audio controls>
                  <source src="./static/audios/chipbagspeech_ours.wav" type="audio/mpeg">
              </audio>
          </div>
      </div>

      <!-- Experiment Setup -->
      <div class="item">
        <!-- <div class="title">Experiment Setup</div> -->
        <img src="./static/images/speaker_rgb.png" alt="Experiment Setup">
        <div class="description">Capturing a speaker while playing MIDI audio of "Mary has a little lamb..."</div>
    </div>

    <!-- Visualized Events -->
    <div class="item">
        <!-- <div class="title">Visualized Events</div> -->
        <img src="./static/images/speaker_event.png" alt="Visualized Events">
        <!-- <div class="description">This is a brief description of the experiment setup.</div> -->
    </div>

    <!-- Microphone -->
    <div class="item">
        <!-- <div class="title">Microphone</div> -->
        <img src="./static/images/midi_microphone.png" alt="Microphone Spectrogram">
        <div class="audio-player">
            <audio controls>
                <source src="./static/audios/midi_microphone.wav" type="audio/mpeg">
            </audio>
        </div>
    </div>

    <!-- Recovered -->
    <div class="item">
        <!-- <div class="title">Recovered</div> -->
        <img src="./static/images/speakermidi_recovered.png" alt="Recovered Spectrogram">
        <div class="audio-player">
            <audio controls>
                <source src="./static/audios/speakermidi_ours.wav" type="audio/mpeg">
            </audio>
        </div>
    </div>

    <!-- Experiment Setup -->
    <div class="item">
      <!-- <div class="title">Experiment Setup</div> -->
      <img src="./static/images/speaker_rgb.png" alt="Experiment Setup">
      <div class="description">Capturing a speaker while playing Speech of "Mary has a little lamb..."</div>
  </div>

  <!-- Visualized Events -->
  <div class="item">
      <!-- <div class="title">Visualized Events</div> -->
      <img src="./static/images/speaker_event.png" alt="Visualized Events">
      <!-- <div class="description">This is a brief description of the experiment setup.</div> -->
  </div>

  <!-- Microphone -->
  <div class="item">
      <!-- <div class="title">Microphone</div> -->
      <img src="./static/images/speech_microphone.png" alt="Microphone Spectrogram">
      <div class="audio-player">
          <audio controls>
              <source src="./static/audios/speech_microphone.wav" type="audio/mpeg">
          </audio>
      </div>
  </div>

  <!-- Recovered -->
  <div class="item">
      <!-- <div class="title">Recovered</div> -->
      <img src="./static/images/speakerspeech_recovered.png" alt="Recovered Spectrogram">
      <div class="audio-player">
          <audio controls>
              <source src="./static/audios/speakerspeech_ours.wav" type="audio/mpeg">
          </audio>
      </div>
  </div>
    </section>
</body>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
